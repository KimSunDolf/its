# 本番環境のベストプラクティス

このガイドでは、プロトタイプから本番環境への移行に役立つベスト プラクティスの包括的なセットを提供します。経験豊富な機械学習エンジニアであろうと、最近熱心な機械学習エンジニアであろうと、このガイドは、API へのアクセスの保護から高トラフィックを処理できる堅牢なアーキテクチャの設計まで、プラットフォームを本番環境で正常に実行するために必要なツールを提供します。このガイドを使用して、アプリケーションをできるだけスムーズかつ効率的にデプロイする計画を立ててください。

## 組織を設定

OpenAI アカウントに[ログインする](https://platform.openai.com/login)と、組織設定で[組織名と](https://platform.openai.com/account/org-settings)ID を見つけることができます。組織名は組織のラベルであり、ユーザー インターフェイスに表示されます。組織 ID は、組織の一意の識別子であり、API 要求で使用できます。

複数の組織に属するユーザーは、API 要求に使用する組織を指定する[ヘッダーを渡す](https://platform.openai.com/docs/api-reference/requesting-organization)ことができます。これらの API リクエストの使用は、割り当てられた組織のクォータに対してカウントされます。ヘッダーが指定されていない場合、[デフォルトの組織](https://platform.openai.com/account/api-keys)に請求されます。[ユーザー設定](https://platform.openai.com/account/api-keys)でデフォルトの組織を変更できます。

[メンバー設定ページから新しいメンバーを](https://platform.openai.com/account/members)組織に招待できます。メンバーは、**読者**または**所有者**になることができます。リーダーは API リクエストを作成し、組織に関する基本情報を表示できますが、所有者は請求情報を変更し、組織内のメンバーを管理できます。

### 料金計算の制限を管理

新しい無料試用版ユーザーは、3 か月で有効期限が切れる最初の $5 のクレジットを受け取ります。クレジットが使用済みまたは期限切れになったら、[請求情報を](https://platform.openai.com/account/billing/overview)入力してAPI を引き続き使用することを選択できます。お支払い情報が入力されていない場合でもログイン アクセスはできますが、それ以上 API リクエストを行うことはできません。

お支払い情報を入力すると、OpenAI によって設定された月額 120 ドルの使用制限が承認されます。1 か月の請求上限 $120 を超えて割り当てを増やすには、[割り当て増加リクエスト](https://platform.openai.com/forms/quota-increase)を送信します。

使用量が一定量を超えたときに通知を受け取りたい場合は、\[使用制限\] ページでソフト[リミット](https://platform.openai.com/account/billing/limits)を設定できます。ソフト制限に達すると、組織の所有者は電子メール通知を受け取ります。ハード リミットを設定して、ハード リミットに達すると、以降の API リクエストが拒否されるようにすることもできます。これらの制限はベスト エフォートであり、使用してから制限が適用されるまでに 5 ～ 10 分の遅延が生じる場合があることに注意してください。

### APIキー

OpenAI API は、認証に API キーを使用します。API キー ページにアクセスして、リクエストで使用する[API キー](https://platform.openai.com/account/api-keys)を取得します。

これはアクセスをコントロールする比較的簡単な方法だが、あなたはこれらの鍵を保護することを警戒しなければならない。コードや公共リポジトリでAPIキーを公開することを避けてください。逆に、安全な場所に保存してください。環境変数や機密管理サービスを使ってアプリケーションに鍵を公開すべきです。そうすれば、コードベースで鍵をハードコードする必要はありません。詳細については、私たちの[APIキーセキュリティベストプラクティス](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-Safety)。
### 一時預かり口座

拡張する時、過渡環境と生産環境のための独立した組織を作る必要があるかもしれない。注意してください。2つの別々のメールアドレス(例えば bob+prod@widgetcorp.com](mailto:bob+prod@widgetcorp.com)と[bob+dev@widgetcoRp.com](mailto:bob+dev@widgetcorp.com))登録して2つの組織を作る。これは開発とテスト作業を隔離することができます。そうすれば、あなたのリアルタイムアプリケーションを意外に中断しません。あなたはまた、この方法で生産組織へのアクセスを制限することができる。

##　原型を構築

もしまだクイックスタートガイドを読んでいないなら、まず[入門ガイド](https://platform.openai.com/docs/quickstart)から始めてから、このガイドの残りの部分を深く読むことをお勧めします。

OpenAI APIに触れたばかりの人にとって、私たちの[遊園地](https://platform.openai.com/playground)はその機能を探索する素晴らしい資源になることができます。そうすることで、何が可能で、どこに集中したいのかを理解するのに役立つでしょう。私たちの[例のヒント](https://platform.openai.com/examples)もご覧ください。

遊園地は原型を作るのに良い場所ですが、大型プロジェクトの孵化場としても活用できます。遊園地はAPIが要求したコードの断片を簡単にエクスポートし、協力者とヒントを共有し、開発過程に不可欠な部分になります。

### その他のヒント

1.**まず**あなたがアプリケーションに望むコア機能を確認する。あなたが必要とするデータ入力、出力、プロセスの種類を考慮してください。あなたが迅速かつ効果的に反復できるように、プロトタイプをできるだけ集中させるように設計されました。

2.**あなたが最も熟知している**で、あなたのプロジェクトの目標に最も合うプログラミング言語とフレームワークを選んでください。いくつかの人気のあるオプションはPython、Java、Node.jsを含む。ライブラリサポートページを参照して、私たちのチームとより広い開発者コミュニティが維持する[ライブラリ](https://platform.openai.com/docs/libraries/community-libraries)について調べてください。もっと多くの情報を決めます。

3.開発**環境とサポート**:正しいツールとライブラリを使って開発環境を設定し、訓練モデルに必要な資源を確保する。私たちの文書、[コミュニティフォーラム](https://community.openai.com/)とヘルプセンターを利用して故障排除[ヘルプ](https://help.openai.com/)を取得します。Pythonで開発しているなら、この構造化プロジェクトガイドを確認してください(リポジトリ構造は[プロジェクト](https://docs.python-guide.org/writing/structure/)アーキテクチャの核心部分です)。私たちのサポートエンジニアに連絡するには、あなたのアカウントにログインして「ヘルプ」ボタンで会話を始めるだけです。

###　ヒントの信頼性を高める技術

慎重に計画しても、アプリケーションでGPT-3を使用する時、意外な問題に備えることが大切です。場合によっては、モデルが任務に失敗する可能性があるので、アプリケーションの信頼性を高めるためにどんな操作ができるかを考えるのが役に立ちます。

もしあなたの任務が論理的推論や複雑性にかかわるなら、より信頼できるヒントを構築するために他のステップを取る必要があるかもしれません。いくつかの有用なアドバイスについては、私たちの[信頼性を高める技術](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve)を参照してください。_Reliability.md)ガイド。全体的に、提案は以下をめぐる。

- 信頼できない操作をより小さく、より信頼できる操作に分解する(例えば、[選択推理ヒント](https://github.com/openai/openai-cookbook/blob/main/techniques_to_Improve_reliability.md#selection-inference-prompting))
- 複数のステップまたは複数の関係を使ってシステムの信頼性をどの単一コンポーネントよりも高くする(例えば、[maieuticヒント](https://github.com/openai/openai-cookbook/blob/main/teChniques_to_improve_reliability.md#maieutic-prompting))

##　評価と反復

生産システムを開発する最も重要な側面の一つは、定期的な評価と反復実験である。この過程は性能を測定し、問題を解決し、モデルを微調整して正確性と効率を向上させることができます。この過程の核心部分は機能のための評価データセットを作ることだ。以下は覚えておくべきいくつかの点です。

1.**評価セットが**モデルが現実世界で使用されるデータを代表することを確保します。これは、モデルが今まで見たことのないデータの性能を評価し、新しい状況の一般化の程度を理解するのに役立ちます。

2.**評価セットを定期的に更新し、**モデルの発展と新しいデータの出現に伴う関連性を確保する。

3.**様々な指標を使ってモデルの性能を評価する**。あなたのアプリケーションと業務成果によって、これは正確性、精度、[リコール率、F1点数または平均精度(MAP)を含むかもしれません。](Https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.htMl)また、微調整を[重みと偏差](https://platform.openai.com/docs/guides/fine-tuning/advanced-usage)と同期して、実験、モデルとデータセット。

4.**モデルの性能とベースラインを比較する**。これはモデルの長所と短所をよりよく理解し、将来の開発作業を指導するのに役に立ちます。

定期的な評価と反復実験を通じて、GPT駆動のアプリケーションやプロトタイプが時間とともに絶えず改善されることを保証します。

### 言語モデルを評価

言語モデルは評価が難しいかもしれません。なぜなら、生成された言語の質は通常主観的で、言語で同じメッセージを正しく伝えることができる多くの異なる方法があるからです。例えば、モデルが長いテキストをまとめる能力を評価する時、多くの正しい要約がある。そうは言っても、よく設計された評価は機械学習の進歩に不可欠だ。

評価キットは全面的で、実行しやすく、速度がかなり速い(モデルの大きさによる)が必要です。また、1ヶ月の総合内容が別の月に時代遅れになる可能性があるため、キットに引き続き簡単に追加する必要があります。私たちは拡張によって改善されていないモデルや機能の弱点を識別するために、多様な任務と任務を優先すべきです。

システムを評価する最も簡単な方法は、その出力を手動で確認することです。それは君が望むことをやっているの？出力は高品質ですか?それらは一致していますか？

### 自動評価

テスト速度を速める最善の方法は自動評価を開発することだ。しかし、これはより主観的なアプリケーション(ダイジェストタスクなど)では実現できないかもしれない。

最終出力が正しいか正しくないかを分類しやすい場合、自動評価が最も効果的です。例えば、分類器を微調整してテキスト文字列をA類やB類に分類する場合、かなり簡単です。サンプル入力と出力を使ってテストセットを作り、入力でシステムを実行し、正確な出力に基づいてシステム出力を分類します(正確性、F1スコア、クロスエントロピーなど)。マーク）。

もしあなたの出力が会議録のダイジェストのように半オープンであれば、定義の成功はもっと厄介かもしれません。例えば、一つのダイジェストが他のダイジェストより優れているのは何ですか?ここで、可能な技術は以下を含む：

- 「黄金標準」の答えでテストを作成し、各黄金標準の答えとシステム出力の間のある種の類似性点数を測定する(私たちはすでに[この点に埋め込まれている](https://platform.openai.com/docs/guides/Embeddings)効果が良い)
- 識別器システムを構築して判断/ランキング出力し、その識別器に1セットの出力を与え、そのうちの1つは被測定システムによって生成される(これはGPTモデルで、質問が与えられた出力で正しく答えられるかどうかを尋ねます)
- 評価モデルを構築し、答えの構成要素の真実性をチェックします。例えば、引用が実際に与えられたテキストに現れるかどうかを検査します。

クリエイティブストーリー作家のような非常にオープンなタスクに対して、自動評価はさらに難しい。スペルミス、単語の多様性、可読性点数を調べるために品質指標を開発する可能性があるが、これらの指標は文章の創意的な品質を本当に捉えることはできない。良い自動化指標が見つからない場合、人工評価は依然として最善の方法だ。

### GPT-3に基づいたシステムを評価するサンプルプロセス

一例として、検索に基づいた質疑応答システムを構築する状況を考えてみましょう。

検索に基づいた質疑応答システムには二つの段階がある。まず、ユーザーの問い合わせは知識ベースで関連可能な文書をランキングするのに使われます。第二に、GPT-3は上位の文書を取得し、問い合わせの答えを生成するように要求します。

各段階の性能を測定するために評価することができる。

検索手順については、:

- まず、~100個の問題を含むテストセットを生成し、各問題ごとに正しい文書を生成します。

- もし何か質問があれば、これらの問題はユーザーデータから来ることができます。そうでなければ、スタイルと難易度の異なる問題を発明することができます。

- 各質問に対して、一人に手動で知識ベースを検索させ、答えを含む文書集を記録させてください。

- 次に、テストセットを使ってシステムの性能を採点します。
- 各問題に対して、システムを使って候補文書をランキングする(例えば、文書埋め込みと検索埋め込みの余弦類似性)。

- もし候補文書に少なくとも1つの答えキーからの関連文書が含まれている場合、二進法の正確性点数1で結果を採点することができます。そうでなければ0です。

- Mean Reciprocal Rankなどの連続指標も使用でき、正しい答えに近いか、正確ではない答えを区別するのに役立つ(例えば、正しい文書が1位なら、得点は1、もし2位なら、得点は½、1⁄3、もしランキング3、など)

質疑応答の手順については、:

- まず、~100グループ{問題、関連テキスト、正解}を含むテストセットを生成します。

- 問題と関連テキストについては、上記のデータをご利用ください。
- 正しい答えについて、一人に~100個の例を書いてもらって、良い答えがどんなものか説明してください。


次に、テストセットを使ってシステムの性能を採点します。

- 各質問とテキストペアに対して、それらを一つのヒントに組み合わせ、ヒントをGPT-3に提出します。

- 次に、GPT-3の答えと人間が書いた黄金標準の答えを比較します。

- この比較は手動で可能です。人々は並んでそれらをチェックし、GPT-3の答えが正しい/高品質かどうかを採点します。

- この比較は埋め込み類似性スコアや他の方法を使って自動化することができます(自動化方法は騒音があるかもしれませんが、それが無偏で、あなたがテストしている異なるタイプのモデルでも同じくうるさくて、騒音でいいです)


もちろん、これはただ一つの例です。初期段階では、より簡単に生成できる小さな集合から始めるかもしれませんが、後期段階では、より大きな集合に投資するかもしれません。コストはもっと高いですが、統計的にはもっと信頼できます。`N=100`

## ソリューションアーキテクチャの拡張

私たちのAPIを使って生産環境のためにアプリケーションやサービスを設計する時、トラフィックの需要を満たすためにどのように拡張するかを必ず考えてください。どのクラウドサービスプロバイダを選んでも、いくつかの重要な分野を考慮する必要があります。

- 水平スケール:複数のソースからのアプリケーション要求に適応するために、**水平**横にアプリケーションを拡張したいかもしれません。これは負荷を分配するために他のサーバーやコンテナを配置することを含むかもしれない。このタイプのスケーリングを選択した場合、あなたのアーキテクチャが複数のノードを処理するように設計され、それらの間の負荷をバランスさせる適切なメカニズムがあることを確認してください。

- 垂直拡張:もう一つの選択肢は**垂直垂直拡張**アプリケーションです。これは単一ノードで使用できる資源を強化できるという意味です。これは追加的な負荷を処理するためにサーバーの機能をアップグレードすることを含むだろう。このタイプのスケーリングを選択した場合、アプリケーションがこれらの追加資源を利用するように設計されていることを確認してください。

- **キャッシュ**:頻繁にアクセスするデータを保存することで、私たちのAPIを繰り返し呼び出すことなく、応答時間を短縮することができます。アプリケーションはできるだけキャッシュデータを使用し、新しい情報を追加する時にキャッシュを無効にするように設計する必要があります。これを成し遂げるいくつかの異なる方法がある。例えば、データをデータベース、ファイルシステム、またはメモリのキャッシュに保存することができます。具体的に何がアプリケーションに最も意味があるかによって違います。
- 負荷バランス:最後に、要求が利用可能なサーバーの間で均等に分布されるように、**負荷バランス**技術を考慮します。これはサーバーの前でロードバランサーを使用するか、DNSローテーションメカニズムを使用することを含むかもしれない。負荷のバランスは性能を向上させ、ボトルネックを減らすのに役立つだろう。


## 速度制限を管理

私たちのAPIを使用する時、[速度制限](https://platform.openai.com/docs/guides/rate-limits)を理解し、計画することが非常に重要です。

##　遅延を改善

遅延は要請を処理して応答を返すのに必要な時間だ。このセクションでは、テキスト生成モデルの遅延に影響するいくつかの要因を議論し、遅延を減らす方法に関するアドバイスを提供します。

リクエストの完了の遅延は主に2つの要因によって影響を受けます：モデルと生成されたトークンの数。完了要請のライフサイクルは次の通りです。

ネットワーク

エンドユーザーからAPIへの遅延

サーバー

提示トークンを処理する時間

サーバー

サンプリング/トークンを生成する時間

ネットワーク

エンドユーザーに遅延するAPI

ほとんどの遅延は、通常、トークン生成の手順から来る。

> **直感**:提示トークンが呼び出しを完了するために増加する遅延は非常に小さい。トークンは一度に1つずつ生成されるため、完了トークンを生成するのにはるかに時間がかかる。各トークンは生成する必要があるため、長い生成長さは遅延を蓄積する。

### 遅延を影響する一般的な要因と可能な緩和技術

今、私たちは遅延の基礎知識を理解しました。遅延に影響を及ぼす可能性のある様々な要因を見てみましょう。大体影響が最大から影響が最小までです。

####　型

私たちのAPIは異なる複雑性と汎用性を持つ異なるモデルを提供する。最も強力なモデル(例えば)は、より複雑で多様な完成を生成できますが、検索を処理するのにもっと時間がかかります。のようなモデルはより速く、より安いチャット完了時間を生成できますが、生成した結果は正確ではないか、あなたの問い合わせとあまり関係がないかもしれません。あなたのユースケースに最も適したモデルを選び、速度と品質の間でトレードオフすることができます。`gpt-4``gpt-3.5-turbo`

#### 完成トークン数

大量に生成されたトークンの完了を要求すると、遅延が増加する可能性がある。

- **低い最大**トークン数:似たようなトークン生成カウントを持つ要求に対して、低いパラメータを持つ要求は遅延が少ない。`max_tokens`

- 停止シーケンスを含む:不要なトークンの生成を防ぐには、**停止シーケンス**を追加してください。例えば、停止シーケンスを使って特定の数の項目のリストを生成することができます。この場合、停止シーケンスとして使用することで、10個の項目だけを含むリストを生成することができます。なぜなら、完成は到達時に停止するからです。[停止シーケンスに関する私たちのヘルプ記事を読んで、詳しく知る](https://help.openai.com/en/articles/5072263-how-do-i-use-stop-sequences)どうやってこの操作を実行するか。より多くの文脈を作る。`11.``11.`

- **少ない完成回数**:できるだけwhereの値を下げ、各ヒントごとに生成された完成回数を指し、各トークンの対数確率が最も高い結果を表すのに使われます。`n``best_of``n``best_of`

結果が1に等しい場合(これはデフォルト値)、生成されたトークンの数は最大に等しい。`n``best_of``max_tokens`

もし(返された完成数)または(考慮のために生成された完成数)が設定されれば、各要求は複数の出力が作成されます。ここでは、生成されたトークンの数を`n``best_of``> 1``[ max_tokens * max (n, best_of) ]`とみなすことができます。

#### 流

リクエストで設定すると、完全なトークンシーケンスが生成されるのを待つのではなく、モデルがトークンが利用可能になった時にすぐにトークンを返し始めるようにします。それはすべてのトークンを取得する時間を変更しませんが、私たちが一部の進捗を表示したり、生成されたアプリケーションの最初のトークンを停止したい時間を減らします。これはより良いユーザー体験とユーザー体験の改善になるので、ストリーミングを試してみる価値があります。`stream: true`

#### インフラ

私たちのサーバーは現在アメリカにあります。私たちは将来、グローバル冗長性を実現したいが、同時に、サーバーとOpenAIサーバーの間の往復時間を最小化するために、インフラの関連部分をアメリカに位置づけることを考慮することができます。

#### トッピング

あなたの使用例によって、バッチ処理_は役に立つかもしれない_。同じ端末ノードに複数の要請を送るなら、同じ要請で大量に送ることができる[ヒント](https://platform.openai.com/docs/guides/rate-limits/batching-requEsts)。これはあなたが送らなければならない要請の数を減らすだろう。提示パラメータは最大20個の唯一の提示を収容できる。私たちはあなたがこの方法が役に立つかどうかテストしてみることをお勧めする。場合によっては、最終的に生成されたトークンの数を増やす可能性があり、これは応答時間を遅くします。

## コストを管理

あなたのコストを監視するには、特定の使用閾値を超えた後、電子メールアラートを受け取るために、アカウントにソフト制限を設定することができます。ハードな制限を設定することもできます。ハード制限はアプリケーション/ユーザーに中断を引き起こす可能性があることに注意してください。使用状況[追跡ダッシュボード](https://platform.openai.com/account/usage)現在と過去の請求周期内のトークンの使用状況を監視する。

### テキスト生成

プロトタイプを生産に投入する課題の一つは、アプリケーションを実行するためのコストを予算化することです。OpenAIは[即払いの定価モデル](https://openai.com/api/pricing/)を提供し、1つのトークン当たりの価格(約000単語に等しい)。コストを見積もるには、トークン利用率を予測する必要がある。トラフィックレベル、ユーザーとアプリケーションの相互作用の頻度、処理されるデータ量などを考慮します。

**コスト削減を考慮する有用なフレームワークは、コストをトークンの数と各トークンのコストの関数とみなすことです。**このフレームワークの使用にはコスト削減の2つの潜在的な方法がある。まず、特定のタスクのために小さなモデルに切り替えることでコストを削減し、各トークンのコストを下げることができます。あるいは、あなたは必要なトークンの数を減らすことを試みることができる。この操作を実行するにはいくつかの方法があります。例えば、短いヒント、[微調整](https://platform.openai.com/docs/guides/fine-tuning)モデルや一般的なユーザー検索をキャッシュして、重複する必要がないようにします。それらを整理する。

私たちのインタラクティブ[分詞器ツール](https://platform.openai.com/tokenizer)を使ってコストを見積もることができます。APIと運動場はまた、応答の一部としてトークンカウントを返します。私たちの最も強力なモデルを使用した後、他のモデルがより低い遅延とコストで同じ結果を生み出すことができるかどうかを確認することができます。詳細については、私たちの[トークン使用ヘルプ記事](https://help.openai.com/en/articles/6614209-how-do-i-check-my-token-usage)を参照してください。
## MLOps戦略

プロトタイプを生産に投入する時、MLOps戦略の開発を考慮する必要があるかもしれません。MLOps(機械学習操作)は機械学習モデルのエンドツーエンドライフサイクルを管理する過程を指し、私たちのAPIを使って微調整できるどんなモデルも含まれます。MLOps戦略を設計する時、多くの側面を考慮する必要があります。これらは...を含む。

- データとモデル管理:訓練や微調整モデルのためのデータを管理し、バージョンと変更を追跡します。

- モデル監視:モデルが時間とともに変化する性能を追跡し、いかなる潜在的な問題や降格も検出します。

- モデル再訓練:モデルがデータの変化や変化する需要と同期することを確保し、必要に応じて再訓練したり、微調整したりします。

- モデル配置:モデルと関連プロジェクトを生産に配置する過程を自動的に実行します。


アプリケーションのこれらの側面を慎重に考慮することは、モデルが関連性を維持し、時間とともに良いパフォーマンスを発揮することを保証するのに役立つだろう。

## 安全性とコンプライアンス

プロトタイプが本番環境に導入されると、アプリケーションに適用される可能性のあるセキュリティとコンプライアンスの要件を評価して満たす必要があります。これには、処理しているデータを調べ、API がデータを処理する方法を理解し、遵守する必要がある規制を決定することが含まれます。参考までに、当社の[プライバシー ポリシー](https://openai.com/privacy/)と[利用規約](https://openai.com/api/policies/terms/)を以下に示します。

考慮する必要がある一般的な領域には、データ ストレージ、データ転送、データ保持などがあります。暗号化や匿名化 (可能な場合) など、データのプライバシー保護を実装する必要がある場合もあります。また、入力のサニタイズや適切なエラー処理など、安全なコーディングのベスト プラクティスに従ってください。

### セキュリティのベストプラクティス

API を使用してアプリケーションを作成する場合は、[セキュリティのベスト プラクティス](https://platform.openai.com/docs/guides/safety-best-practices)を考慮して、アプリケーションが安全で成功するようにしてください。これらの推奨事項は、製品を広範囲にテストし、潜在的な問題に積極的に対処し、悪用の機会を制限することの重要性を強調しています。